{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af864437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create interaction data\n",
    "interactions = [\n",
    "    {'user_id': 'U1', 'product_id': 'P1', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U1', 'product_id': 'P2', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U2', 'product_id': 'P3', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U2', 'product_id': 'P4', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U3', 'product_id': 'P1', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U3', 'product_id': 'P2', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U3', 'product_id': 'P5', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U4', 'product_id': 'P5', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U4', 'product_id': 'P6', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U5', 'product_id': 'P3', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U5', 'product_id': 'P4', 'interaction_type': 'view', 'weight': 0.5}\n",
    "]\n",
    "interactions_df = pd.DataFrame(interactions)\n",
    "\n",
    "# Create user features\n",
    "users = [\n",
    "    {'user_id': 'U1', 'age': 25, 'preferred_category': 'electronics'},\n",
    "    {'user_id': 'U2', 'age': 35, 'preferred_category': 'clothing'},\n",
    "    {'user_id': 'U3', 'age': 28, 'preferred_category': 'electronics'},\n",
    "    {'user_id': 'U4', 'age': 40, 'preferred_category': 'home_goods'},\n",
    "    {'user_id': 'U5', 'age': 22, 'preferred_category': 'clothing'}\n",
    "]\n",
    "users_df = pd.DataFrame(users)\n",
    "\n",
    "# Create product features\n",
    "products = [\n",
    "    {'product_id': 'P1', 'name': 'Smartphone', 'category': 'electronics', 'price': 500},\n",
    "    {'product_id': 'P2', 'name': 'Laptop', 'category': 'electronics', 'price': 1000},\n",
    "    {'product_id': 'P3', 'name': 'T-shirt', 'category': 'clothing', 'price': 20},\n",
    "    {'product_id': 'P4', 'name': 'Jeans', 'category': 'clothing', 'price': 50},\n",
    "    {'product_id': 'P5', 'name': 'Lamp', 'category': 'home_goods', 'price': 40},\n",
    "    {'product_id': 'P6', 'name': 'Blender', 'category': 'home_goods', 'price': 80}\n",
    "]\n",
    "products_df = pd.DataFrame(products)\n",
    "\n",
    "# Normalize numerical features\n",
    "products_df['price_normalized'] = products_df['price'] / products_df['price'].max()\n",
    "users_df['age_normalized'] = users_df['age'] / users_df['age'].max()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "user_categories = pd.get_dummies(users_df['preferred_category'], prefix='prefers')\n",
    "users_df = pd.concat([users_df, user_categories], axis=1)\n",
    "\n",
    "product_categories = pd.get_dummies(products_df['category'], prefix='category')\n",
    "products_df = pd.concat([products_df, product_categories], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e987108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "\n",
    "# Create a bipartite graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add user nodes with features\n",
    "for _, user in users_df.iterrows():\n",
    "    G.add_node(user['user_id'], \n",
    "               type='user',\n",
    "               age=user['age_normalized'],\n",
    "               prefers_electronics=user['prefers_electronics'] if 'prefers_electronics' in user else 0,\n",
    "               prefers_clothing=user['prefers_clothing'] if 'prefers_clothing' in user else 0,\n",
    "               prefers_home_goods=user['prefers_home_goods'] if 'prefers_home_goods' in user else 0)\n",
    "\n",
    "# Add product nodes with features\n",
    "for _, product in products_df.iterrows():\n",
    "    G.add_node(product['product_id'], \n",
    "               type='product',\n",
    "               price=product['price_normalized'],\n",
    "               category_electronics=product['category_electronics'],\n",
    "               category_clothing=product['category_clothing'],\n",
    "               category_home_goods=product['category_home_goods'])\n",
    "\n",
    "# Add edges based on interactions\n",
    "for _, interaction in interactions_df.iterrows():\n",
    "    G.add_edge(interaction['user_id'], interaction['product_id'], weight=interaction['weight'])\n",
    "\n",
    "# Preparing data for PyTorch Geometric\n",
    "# Create mappings for user and product IDs\n",
    "user_mapping = {user_id: idx for idx, user_id in enumerate(G.nodes()) if G.nodes[user_id]['type'] == 'user'}\n",
    "product_mapping = {prod_id: idx for idx, prod_id in enumerate(G.nodes()) if G.nodes[prod_id]['type'] == 'product'}\n",
    "\n",
    "# Create edge index\n",
    "edge_index = []\n",
    "edge_weights = []\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if G.nodes[u]['type'] == 'user':\n",
    "        edge_index.append([user_mapping[u], product_mapping[v]])\n",
    "    else:\n",
    "        edge_index.append([user_mapping[v], product_mapping[u]])\n",
    "    edge_weights.append(data['weight'])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "\n",
    "# Create node features\n",
    "user_features = torch.tensor([[G.nodes[u]['age'], \n",
    "                              G.nodes[u]['prefers_electronics'],\n",
    "                              G.nodes[u]['prefers_clothing'],\n",
    "                              G.nodes[u]['prefers_home_goods']] \n",
    "                             for u in user_mapping], dtype=torch.float)\n",
    "\n",
    "product_features = torch.tensor([[G.nodes[p]['price'],\n",
    "                                 G.nodes[p]['category_electronics'],\n",
    "                                 G.nodes[p]['category_clothing'],\n",
    "                                 G.nodes[p]['category_home_goods']] \n",
    "                                for p in product_mapping], dtype=torch.float)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = HeteroData()\n",
    "data['user'].x = user_features\n",
    "data['product'].x = product_features\n",
    "data['user', 'interacts', 'product'].edge_index = edge_index\n",
    "data['user', 'interacts', 'product'].edge_attr = edge_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7138c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import HeteroConv, GCNConv\n",
    "\n",
    "class GraphSAGERecommender(nn.Module):\n",
    "    def __init__(self, user_features, product_features, embedding_dim=64, hidden_dim=32):\n",
    "        super(GraphSAGERecommender, self).__init__()\n",
    "        \n",
    "        # Input feature dimensions\n",
    "        self.user_feature_dim = user_features.shape[1]\n",
    "        self.product_feature_dim = product_features.shape[1]\n",
    "        \n",
    "        # First layer: transform node features into embeddings\n",
    "        self.user_encoder = nn.Linear(self.user_feature_dim, embedding_dim)\n",
    "        self.product_encoder = nn.Linear(self.product_feature_dim, embedding_dim)\n",
    "        \n",
    "        # GraphSAGE convolutional layers\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'interacts', 'product'): SAGEConv(embedding_dim, hidden_dim),\n",
    "            ('product', 'rev_interacts', 'user'): SAGEConv(embedding_dim, hidden_dim)\n",
    "        })\n",
    "        \n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'interacts', 'product'): SAGEConv(hidden_dim, hidden_dim),\n",
    "            ('product', 'rev_interacts', 'user'): SAGEConv(hidden_dim, hidden_dim)\n",
    "        })\n",
    "        \n",
    "        # Final prediction layer\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_dict, edge_indices_dict):\n",
    "        # Initial embeddings from features\n",
    "        x_dict['user'] = F.relu(self.user_encoder(x_dict['user']))\n",
    "        x_dict['product'] = F.relu(self.product_encoder(x_dict['product']))\n",
    "        \n",
    "        # First message passing layer\n",
    "        x_dict = self.conv1(x_dict, edge_indices_dict)\n",
    "        x_dict = {key: F.relu(value) for key, value in x_dict.items()}\n",
    "        \n",
    "        # Second message passing layer\n",
    "        x_dict = self.conv2(x_dict, edge_indices_dict)\n",
    "        x_dict = {key: F.relu(value) for key, value in x_dict.items()}\n",
    "        \n",
    "        return x_dict\n",
    "    \n",
    "    def predict(self, user_emb, product_emb):\n",
    "        # Concatenate user and product embeddings\n",
    "        pair_emb = torch.cat([user_emb, product_emb], dim=1)\n",
    "        # Predict interaction probability\n",
    "        return torch.sigmoid(self.predictor(pair_emb))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b607bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "def train_model(model, data, epochs=100, lr=0.01, batch_size=64):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Split data into train/validation\n",
    "    # (For simplicity, we're using all data for training in this example)\n",
    "    # In a real scenario, you would use proper train/val/test splits\n",
    "    \n",
    "    train_loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors={\n",
    "            ('user', 'interacts', 'product'): [5],\n",
    "            ('product', 'rev_interacts', 'user'): [5]\n",
    "        },\n",
    "        batch_size=batch_size,\n",
    "        input_nodes=('user', None)\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            embeddings = model(batch.x_dict, batch.edge_index_dict)\n",
    "            \n",
    "            # Get user-product pairs from batch\n",
    "            user_idx, product_idx = batch.edge_index_dict[('user', 'interacts', 'product')]\n",
    "            \n",
    "            # Get embeddings for the connected pairs\n",
    "            user_embs = embeddings['user'][user_idx]\n",
    "            product_embs = embeddings['product'][product_idx]\n",
    "            \n",
    "            # Predict interactions for these pairs\n",
    "            pred = model.predict(user_embs, product_embs).squeeze()\n",
    "            \n",
    "            # Ground truth - edge weights as target (1.0 for purchase, 0.5 for view)\n",
    "            target = batch.edge_attr_dict[('user', 'interacts', 'product')].float()\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(pred, target)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bd16ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, data, user_id, user_mapping, product_mapping, interactions_df, top_k=5):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Get index for the specified user ID\n",
    "    user_idx = list(user_mapping.keys()).index(user_id)\n",
    "    \n",
    "    # Run model forward pass to get embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Get the embedding for our target user\n",
    "    user_embedding = embeddings['user'][user_idx].unsqueeze(0)\n",
    "    \n",
    "    # Calculate scores for all products\n",
    "    product_embeddings = embeddings['product']\n",
    "    \n",
    "    # For each product, calculate prediction score\n",
    "    scores = []\n",
    "    for prod_idx in range(len(product_mapping)):\n",
    "        prod_embedding = product_embeddings[prod_idx].unsqueeze(0)\n",
    "        score = model.predict(user_embedding, prod_embedding).item()\n",
    "        product_id = list(product_mapping.keys())[prod_idx]\n",
    "        scores.append((product_id, score))\n",
    "    \n",
    "    # Sort by score (descending) and get top-k\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Filter out products the user has already interacted with\n",
    "    existing_interactions = set(interactions_df[interactions_df['user_id'] == user_id]['product_id'])\n",
    "    recommendations = [(prod_id, score) for prod_id, score in scores if prod_id not in existing_interactions][:top_k]\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39333d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, test_interactions):\n",
    "    model.eval()\n",
    "    \n",
    "    # Metrics\n",
    "    precision_k = 0\n",
    "    recall_k = 0\n",
    "    ndcg_k = 0\n",
    "    k = 10  # top-k recommendations\n",
    "    \n",
    "    # Get all user embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Calculate metrics for each user\n",
    "    for user_id in user_mapping.keys():\n",
    "        # Get ground truth interactions from test set\n",
    "        true_interactions = set(test_interactions[test_interactions['user_id'] == user_id]['product_id'])\n",
    "        \n",
    "        if not true_interactions:\n",
    "            continue  # Skip users with no test interactions\n",
    "        \n",
    "        # Get recommendations\n",
    "        recommended_products = get_recommendations(model, data, user_id, top_k=k)\n",
    "        \n",
    "        # Calculate precision@k\n",
    "        hits = len(set(recommended_products) & true_interactions)\n",
    "        precision_k += hits / k\n",
    "        \n",
    "        # Calculate recall@k\n",
    "        recall_k += hits / len(true_interactions)\n",
    "        \n",
    "        # NDCG calculation would go here\n",
    "        \n",
    "    # Average metrics\n",
    "    num_users = len(user_mapping)\n",
    "    precision_k /= num_users\n",
    "    recall_k /= num_users\n",
    "    \n",
    "    return {\n",
    "        f'precision@{k}': precision_k,\n",
    "        f'recall@{k}': recall_k\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4e29f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions DataFrame:\n",
      "  user_id product_id interaction_type  weight\n",
      "0      U1         P1         purchase     1.0\n",
      "1      U1         P2             view     0.5\n",
      "2      U2         P3         purchase     1.0\n",
      "3      U2         P4             view     0.5\n",
      "4      U3         P1         purchase     1.0\n",
      "\n",
      "Users DataFrame:\n",
      "  user_id  age preferred_category\n",
      "0      U1   25        electronics\n",
      "1      U2   35           clothing\n",
      "2      U3   28        electronics\n",
      "3      U4   40         home_goods\n",
      "4      U5   22           clothing\n",
      "\n",
      "Products DataFrame:\n",
      "  product_id        name     category  price\n",
      "0         P1  Smartphone  electronics    500\n",
      "1         P2      Laptop  electronics   1000\n",
      "2         P3     T-shirt     clothing     20\n",
      "3         P4       Jeans     clothing     50\n",
      "4         P5        Lamp   home_goods     40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulate a database with interactions, users, and products data\n",
    "# Interactions table\n",
    "interactions_data = [\n",
    "    {'user_id': 'U1', 'product_id': 'P1', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U1', 'product_id': 'P2', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U2', 'product_id': 'P3', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U2', 'product_id': 'P4', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U3', 'product_id': 'P1', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U3', 'product_id': 'P2', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U3', 'product_id': 'P5', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U4', 'product_id': 'P5', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "    {'user_id': 'U4', 'product_id': 'P6', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U5', 'product_id': 'P3', 'interaction_type': 'view', 'weight': 0.5},\n",
    "    {'user_id': 'U5', 'product_id': 'P4', 'interaction_type': 'view', 'weight': 0.5}\n",
    "]\n",
    "interactions_df = pd.DataFrame(interactions_data)\n",
    "\n",
    "# Users table\n",
    "users_data = [\n",
    "    {'user_id': 'U1', 'age': 25, 'preferred_category': 'electronics'},\n",
    "    {'user_id': 'U2', 'age': 35, 'preferred_category': 'clothing'},\n",
    "    {'user_id': 'U3', 'age': 28, 'preferred_category': 'electronics'},\n",
    "    {'user_id': 'U4', 'age': 40, 'preferred_category': 'home_goods'},\n",
    "    {'user_id': 'U5', 'age': 22, 'preferred_category': 'clothing'}\n",
    "]\n",
    "users_df = pd.DataFrame(users_data)\n",
    "\n",
    "# Products table\n",
    "products_data = [\n",
    "    {'product_id': 'P1', 'name': 'Smartphone', 'category': 'electronics', 'price': 500},\n",
    "    {'product_id': 'P2', 'name': 'Laptop', 'category': 'electronics', 'price': 1000},\n",
    "    {'product_id': 'P3', 'name': 'T-shirt', 'category': 'clothing', 'price': 20},\n",
    "    {'product_id': 'P4', 'name': 'Jeans', 'category': 'clothing', 'price': 50},\n",
    "    {'product_id': 'P5', 'name': 'Lamp', 'category': 'home_goods', 'price': 40},\n",
    "    {'product_id': 'P6', 'name': 'Blender', 'category': 'home_goods', 'price': 80}\n",
    "]\n",
    "products_df = pd.DataFrame(products_data)\n",
    "\n",
    "# Display the simulated database\n",
    "print(\"Interactions DataFrame:\")\n",
    "print(interactions_df.head())\n",
    "print(\"\\nUsers DataFrame:\")\n",
    "print(users_df.head())\n",
    "print(\"\\nProducts DataFrame:\")\n",
    "print(products_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ddd3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Simulated database (already created in the previous step)\n",
    "    interactions_data = [\n",
    "        {'user_id': 'U1', 'product_id': 'P1', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "        {'user_id': 'U1', 'product_id': 'P2', 'interaction_type': 'view', 'weight': 0.5},\n",
    "        {'user_id': 'U2', 'product_id': 'P3', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "        {'user_id': 'U2', 'product_id': 'P4', 'interaction_type': 'view', 'weight': 0.5},\n",
    "        {'user_id': 'U3', 'product_id': 'P1', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "        {'user_id': 'U3', 'product_id': 'P2', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "        {'user_id': 'U3', 'product_id': 'P5', 'interaction_type': 'view', 'weight': 0.5},\n",
    "        {'user_id': 'U4', 'product_id': 'P5', 'interaction_type': 'purchase', 'weight': 1.0},\n",
    "        {'user_id': 'U4', 'product_id': 'P6', 'interaction_type': 'view', 'weight': 0.5},\n",
    "        {'user_id': 'U5', 'product_id': 'P3', 'interaction_type': 'view', 'weight': 0.5},\n",
    "        {'user_id': 'U5', 'product_id': 'P4', 'interaction_type': 'view', 'weight': 0.5}\n",
    "    ]\n",
    "    interactions_df = pd.DataFrame(interactions_data)\n",
    "\n",
    "    users_data = [\n",
    "        {'user_id': 'U1', 'age': 25, 'preferred_category': 'electronics'},\n",
    "        {'user_id': 'U2', 'age': 35, 'preferred_category': 'clothing'},\n",
    "        {'user_id': 'U3', 'age': 28, 'preferred_category': 'electronics'},\n",
    "        {'user_id': 'U4', 'age': 40, 'preferred_category': 'home_goods'},\n",
    "        {'user_id': 'U5', 'age': 22, 'preferred_category': 'clothing'}\n",
    "    ]\n",
    "    users_df = pd.DataFrame(users_data)\n",
    "\n",
    "    products_data = [\n",
    "        {'product_id': 'P1', 'name': 'Smartphone', 'category': 'electronics', 'price': 500},\n",
    "        {'product_id': 'P2', 'name': 'Laptop', 'category': 'electronics', 'price': 1000},\n",
    "        {'product_id': 'P3', 'name': 'T-shirt', 'category': 'clothing', 'price': 20},\n",
    "        {'product_id': 'P4', 'name': 'Jeans', 'category': 'clothing', 'price': 50},\n",
    "        {'product_id': 'P5', 'name': 'Lamp', 'category': 'home_goods', 'price': 40},\n",
    "        {'product_id': 'P6', 'name': 'Blender', 'category': 'home_goods', 'price': 80}\n",
    "    ]\n",
    "    products_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Normalize numerical features\n",
    "    products_df['price_normalized'] = products_df['price'] / products_df['price'].max()\n",
    "    users_df['age_normalized'] = users_df['age'] / users_df['age'].max()\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    user_categories = pd.get_dummies(users_df['preferred_category'], prefix='prefers')\n",
    "    users_df = pd.concat([users_df, user_categories], axis=1)\n",
    "\n",
    "    product_categories = pd.get_dummies(products_df['category'], prefix='category')\n",
    "    products_df = pd.concat([products_df, product_categories], axis=1)\n",
    "\n",
    "    return interactions_df, users_df, products_df\n",
    "\n",
    "def build_graph(interactions_df, users_df, products_df):\n",
    "    import networkx as nx\n",
    "    import torch\n",
    "    from torch_geometric.data import HeteroData\n",
    "    \n",
    "    # Create a bipartite graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add user nodes with features\n",
    "    for _, user in users_df.iterrows():\n",
    "        G.add_node(user['user_id'], \n",
    "                   type='user',\n",
    "                   age=user['age_normalized'],\n",
    "                   prefers_clothing=user['prefers_clothing'],\n",
    "                   prefers_electronics=user['prefers_electronics'],\n",
    "                   prefers_home_goods=user['prefers_home_goods'])\n",
    "    \n",
    "    # Add product nodes with features\n",
    "    for _, product in products_df.iterrows():\n",
    "        G.add_node(product['product_id'], \n",
    "                   type='product',\n",
    "                   price=product['price_normalized'],\n",
    "                   category_clothing=product['category_clothing'],\n",
    "                   category_electronics=product['category_electronics'],\n",
    "                   category_home_goods=product['category_home_goods'])\n",
    "    \n",
    "    # Add edges based on interactions\n",
    "    for _, interaction in interactions_df.iterrows():\n",
    "        G.add_edge(interaction['user_id'], interaction['product_id'], weight=interaction['weight'])\n",
    "    \n",
    "    # Preparing data for PyTorch Geometric\n",
    "    user_mapping = {user_id: idx for idx, user_id in enumerate([n for n, d in G.nodes(data=True) if d['type'] == 'user'])}\n",
    "    product_mapping = {prod_id: idx for idx, prod_id in enumerate([n for n, d in G.nodes(data=True) if d['type'] == 'product'])}\n",
    "    \n",
    "    edge_index = []\n",
    "    edge_weights = []\n",
    "    \n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if G.nodes[u]['type'] == 'user':\n",
    "            edge_index.append([user_mapping[u], product_mapping[v]])\n",
    "        else:\n",
    "            edge_index.append([user_mapping[v], product_mapping[u]])\n",
    "        edge_weights.append(data['weight'])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t()\n",
    "    edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "    \n",
    "    user_features = torch.tensor([[G.nodes[u]['age'], \n",
    "                                  G.nodes[u]['prefers_clothing'],\n",
    "                                  G.nodes[u]['prefers_electronics'],\n",
    "                                  G.nodes[u]['prefers_home_goods']] \n",
    "                                 for u in user_mapping], dtype=torch.float)\n",
    "    \n",
    "    product_features = torch.tensor([[G.nodes[p]['price'],\n",
    "                                     G.nodes[p]['category_clothing'],\n",
    "                                     G.nodes[p]['category_electronics'],\n",
    "                                     G.nodes[p]['category_home_goods']] \n",
    "                                    for p in product_mapping], dtype=torch.float)\n",
    "    \n",
    "    data = HeteroData()\n",
    "    data['user'].x = user_features\n",
    "    data['product'].x = product_features\n",
    "    \n",
    "    # Add forward edges (user to product)\n",
    "    data['user', 'interacts', 'product'].edge_index = edge_index\n",
    "    data['user', 'interacts', 'product'].edge_attr = edge_weights\n",
    "    \n",
    "    # Add reverse edges (product to user) - THIS IS THE KEY FIX\n",
    "    data['product', 'rev_interacts', 'user'].edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n",
    "    data['product', 'rev_interacts', 'user'].edge_attr = edge_weights\n",
    "    \n",
    "    # Return all necessary objects\n",
    "    return data, user_mapping, product_mapping, interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59dec250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Building graph...\n",
      "Creating model...\n",
      "Training model...\n",
      "Epoch 10/100, Loss: nan\n",
      "Epoch 20/100, Loss: nan\n",
      "Epoch 30/100, Loss: nan\n",
      "Epoch 40/100, Loss: nan\n",
      "Epoch 50/100, Loss: nan\n",
      "Epoch 60/100, Loss: nan\n",
      "Epoch 70/100, Loss: nan\n",
      "Epoch 80/100, Loss: nan\n",
      "Epoch 90/100, Loss: nan\n",
      "Epoch 100/100, Loss: nan\n",
      "\n",
      "Generating recommendations:\n",
      "\n",
      "Recommendations for U1:\n",
      "  1. Lamp (score: 0.5032)\n",
      "  2. Jeans (score: 0.5020)\n",
      "  3. T-shirt (score: 0.5020)\n",
      "  4. Blender (score: 0.5016)\n",
      "\n",
      "Recommendations for U2:\n",
      "  1. Lamp (score: 0.5009)\n",
      "  2. Laptop (score: 0.5007)\n",
      "  3. Blender (score: 0.5003)\n",
      "  4. Smartphone (score: 0.5002)\n",
      "\n",
      "Recommendations for U3:\n",
      "  1. Jeans (score: 0.5027)\n",
      "  2. T-shirt (score: 0.5027)\n",
      "  3. Blender (score: 0.5022)\n",
      "\n",
      "Recommendations for U4:\n",
      "  1. Laptop (score: 0.5006)\n",
      "  2. Smartphone (score: 0.5005)\n",
      "  3. Jeans (score: 0.4995)\n",
      "  4. T-shirt (score: 0.4995)\n",
      "\n",
      "Recommendations for U5:\n",
      "  1. Lamp (score: 0.5013)\n",
      "  2. Laptop (score: 0.5010)\n",
      "  3. Smartphone (score: 0.5006)\n",
      "  4. Blender (score: 0.5003)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Step 1: Prepare data\n",
    "    print(\"Preparing data...\")\n",
    "    interactions_df, users_df, products_df = prepare_data()\n",
    "    \n",
    "    # Step 2: Build graph\n",
    "    print(\"Building graph...\")\n",
    "    data, user_mapping, product_mapping, interactions_df = build_graph(\n",
    "        interactions_df, users_df, products_df\n",
    "    )\n",
    "    \n",
    "    # Step 3: Create model\n",
    "    print(\"Creating model...\")\n",
    "    model = GraphSAGERecommender(data['user'].x, data['product'].x)\n",
    "    \n",
    "    # Step 4: Train model\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(model, data, epochs=100)\n",
    "    \n",
    "    # Step 5: Generate recommendations for each user\n",
    "    print(\"\\nGenerating recommendations:\")\n",
    "    for user_id in user_mapping:\n",
    "        recommendations = get_recommendations(\n",
    "            model, data, user_id, user_mapping, product_mapping, interactions_df\n",
    "        )\n",
    "        \n",
    "        # Display recommendations with product names\n",
    "        print(f\"\\nRecommendations for {user_id}:\")\n",
    "        for i, (prod_id, score) in enumerate(recommendations, 1):\n",
    "            product_name = products_df.loc[products_df['product_id'] == prod_id, 'name'].values[0]\n",
    "            print(f\"  {i}. {product_name} (score: {score:.4f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
